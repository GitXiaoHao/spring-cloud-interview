# 远程调用
## 负载均衡原理
- 在SpringCloud的早期版本中，负载均衡都是有Netflix公司开源的Ribbon组件来实现的，甚至Ribbon被直接集成到了Eureka-client和Nacos-Discovery中。
- 但是自SpringCloud2020版本开始，已经弃用Ribbon，改用Spring自己开源的Spring Cloud LoadBalancer了，我们使用的OpenFeign的也已经与其整合。
  - 从请求的URI中找出serviceId
  - 利用loadBalancerClient，根据serviceId做负载均衡，选出一个实例ServiceInstance
  - 用选中的ServiceInstance的ip和port替代serviceId，重构URI
  - 向真正的URI发送请求
### 流程梳理
- 根据之前的分析，我们会发现Spring在整合OpenFeign的时候，实现了org.springframework.cloud.openfeign.loadbalancer.FeignBlockingLoadBalancerClient类，其中定义了OpenFeign发起远程调用的核心流程。也就是四步：
  - 获取请求中的serviceId
  - 根据serviceId负载均衡，找出一个可用的服务实例
  - 利用服务实例的ip和port信息重构url
  - 向真正的url发起请求
- 而具体的负载均衡则是不是由OpenFeign组件负责。而是分成了负载均衡的接口规范，以及负载均衡的具体实现两部分。
  负载均衡的接口规范是定义在Spring-Cloud-Common模块中，包含下面的接口：
  - LoadBalancerClient：负载均衡客户端，职责是根据serviceId最终负载均衡，选出一个服务实例
  - ReactiveLoadBalancer：负载均衡器，负责具体的负载均衡算法
- OpenFeign的负载均衡是基于Spring-Cloud-Common模块中的负载均衡规则接口，并没有写死具体实现。这就意味着以后还可以拓展其它各种负载均衡的实现。
  不过目前SpringCloud中只有Spring-Cloud-Loadbalancer这一种实现。
- Spring-Cloud-Loadbalancer模块中，实现了Spring-Cloud-Common模块的相关接口，具体如下：
  - BlockingLoadBalancerClient：实现了LoadBalancerClient，会根据serviceId选出负载均衡器并调用其算法实现负载均衡。
  - RoundRobinLoadBalancer：基于轮询算法实现了ReactiveLoadBalancer
  - RandomLoadBalancer：基于随机算法实现了ReactiveLoadBalancer，
![openfeign1.png](openfeign1.png)
![openfeign2.png](openfeign2.png)
## 修改负载均衡策略
- 查看源码会发现，Spring-Cloud-Loadbalancer模块中有一个自动配置类
![openfeign3.png](openfeign3.png)
- 其中定义了默认的负载均衡器
```Java
 @Bean
    @ConditionalOnMissingBean
    public ReactorLoadBalancer<ServiceInstance> reactorServiceInstanceLoadBalancer(Environment environment, LoadBalancerClientFactory loadBalancerClientFactory) {
        String name = environment.getProperty("loadbalancer.client.name");
        return new RoundRobinLoadBalancer(loadBalancerClientFactory.getLazyProvider(name, ServiceInstanceListSupplier.class), name);
    }
```
- 这个Bean上添加了@ConditionalOnMissingBean注解，也就是说如果我们自定义了这个类型的bean，则负载均衡的策略就会被改变。
```Java
package com.hmall.cart.config;

import com.alibaba.cloud.nacos.NacosDiscoveryProperties;
import com.alibaba.cloud.nacos.loadbalancer.NacosLoadBalancer;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.loadbalancer.core.ReactorLoadBalancer;
import org.springframework.cloud.loadbalancer.core.ServiceInstanceListSupplier;
import org.springframework.cloud.loadbalancer.support.LoadBalancerClientFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.core.env.Environment;

public class OpenFeignConfig {

    @Bean
    public ReactorLoadBalancer<ServiceInstance> reactorServiceInstanceLoadBalancer(
            Environment environment, NacosDiscoveryProperties properties,
            LoadBalancerClientFactory loadBalancerClientFactory) {
        String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
        return new NacosLoadBalancer(
                loadBalancerClientFactory.getLazyProvider(name, ServiceInstanceListSupplier.class), name, properties);
    }

} 
```
- 这个配置类千万不要加@Configuration注解，也不要被SpringBootApplication扫描到。
- 由于这个OpenFeignConfig没有加@Configuration注解，也就没有被Spring加载，因此是不会生效的。接下来，我们要在启动类上通过注解来声明这个配置。
- 有两种做法：
  - 全局配置：对所有服务生效
    - `@LoadBalancerClients(defaultConfiguration = OpenFeignConfig.class)`
  - 局部配置：只对某个服务生效
    - `@LoadBalancerClients({
      @LoadBalancerClient(value = "item-service", configuration = OpenFeignConfig.class)
      })`
## NacosLoadBalancer负载均衡算法 - 集群优先
![naco6.png](naco6.png)
- 这部分代码的大概流程如下：
  - 通过ServiceInstanceListSupplier获取服务实例列表
  - 获取NacosDiscoveryProperties中的clusterName，也就是yml文件中的配置，代表当前服务实例所在集群信息（参考2.2小节，分级模型）
  - 然后利用stream的filter过滤找到被调用的服务实例中与当前服务实例clusterName一致的。简单来说就是服务调用者与服务提供者要在一个集群
### 权重配置
- 我们打开nacos控制台，进入item-service的服务详情页，可以看到每个实例后面都有一个编辑按钮：点击，可以看到一个编辑表单 可以修改权重
## 服务保护
- 在SpringCloud的早期版本中采用的服务保护技术叫做Hystix，不过后来被淘汰，替换为Spring Cloud Circuit Breaker，其底层实现可以是Spring Retry和Resilience4J。
### 线程隔离
- 首先我们来看下线程隔离功能，无论是Hystix还是Sentinel都支持线程隔离。不过其实现方式不同。
- 线程隔离有两种方式实现：
  - 线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果
  - 信号量隔离：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求
![sentinel1.png](sentinel1.png)
- 两者的优缺点如下
![sentinel2.png](sentinel2.png)
- 面试题
![sentinel3.png](sentinel3.png)
### 滑动窗口算法
- 在熔断功能中，需要统计异常请求或慢请求比例，也就是计数。在限流的时候，要统计每秒钟的QPS，同样是计数。可见计数算法在熔断限流中的应用非常多。sentinel中采用的计数器算法就是滑动窗口计数算法。
#### 固定窗口计数
要了解滑动窗口计数算法，我们必须先知道固定窗口计数算法
- 说明：
  - 将时间划分为多个窗口，窗口时间跨度称为Interval，本例中为1000ms；
  - 每个窗口维护1个计数器，每有1次请求就将计数器+1。限流就是设置计数器阈值，本例为3，图中红线标记
  - 如果计数器超过了限流阈值，则超出阈值的请求都被丢弃。
![sentinel4.png](sentinel4.png)
- 说明：
  - 第1、2秒，请求数量都小于3，没问题
  - 第3秒，请求数量为5，超过阈值，超出的请求被拒绝
#### 滑动窗口计数
固定时间窗口算法中窗口有很多，其跨度和位置是与时间区间绑定，因此是很多固定不动的窗口。而滑动时间窗口算法中只包含1个固定跨度的窗口，但窗口是可移动动的，与时间区间无关。

- 具体规则如下：
  - 窗口时间跨度Interval大小固定，例如1秒
  - 时间区间跨度为Interval / n ，例如n=2，则时间区间跨度为500ms
  - 窗口会随着当前请求所在时间currentTime移动，窗口范围从currentTime-Interval时刻之后的第一个时区开始，到currentTime所在时区结束。
- 如图所示：
![sentinel5.png](sentinel5.png)
- 限流阈值依然为3，绿色小块就是请求，上面的数字是其currentTime值。
  - 在第1300ms时接收到一个请求，其所在时区就是1000~1500
  - 按照规则，currentTime-Interval值为300ms，300ms之后的第一个时区是500~1000，因此窗口范围包含两个时区：500~1000、1000~1500，也就是粉红色方框部分
  - 统计窗口内的请求总数，发现是3，未达到上限。
- 若第1400ms又来一个请求，会落在1000~1500时区，虽然该时区请求总数是3，但滑动窗口内总数已经达到4，因此该请求会被拒绝：
- 滑动窗口内划分的时区越多，这种统计就越准确。

### 漏桶算法
- 漏桶算法与令牌桶相似，但在设计上更适合应对并发波动较大的场景，以解决令牌桶中的问题。
- 简单来说就是请求到达后不是直接处理，而是先放入一个队列。而后以固定的速率从队列中取出并处理请求。之所以叫漏桶算法，就是把请求看做水，队列看做是一个漏了的桶。
![sentinel6.png](sentinel6.png)
- 说明：
  - 将每个请求视作"水滴"放入"漏桶"进行存储；
  - "漏桶"以固定速率向外"漏"出请求来执行，如果"漏桶"空了则停止"漏水”；
  - 如果"漏桶"满了则多余的"水滴"会被直接丢弃。
- 漏桶的优势就是流量整型，桶就像是一个大坝，请求就是水。并发量不断波动，就如图水流时大时小，但都会被大坝拦住。而后大坝按照固定的速度放水，避免下游被洪水淹没。
- 因此，不管并发量如何波动，经过漏桶处理后的请求一定是相对平滑的曲线
- sentinel中的限流中的排队等待功能正是基于漏桶算法实现的
### 令牌桶算法
- 限流的另一种常见算法是令牌桶算法。Sentinel中的热点参数限流正是基于令牌桶算法实现的。其基本思路如图
![sentinel7.png](sentinel7.png)
- 说明：
  - 以固定的速率生成令牌，存入令牌桶中，如果令牌桶满了以后，多余令牌丢弃
  - 请求进入后，必须先尝试从桶中获取令牌，获取到令牌后才可以被处理
  - 如果令牌桶中没有令牌，则请求等待或丢弃
- 基于令牌桶算法，每秒产生的令牌数量基本就是QPS上限。 
- 当然也有例外情况，例如：
  - 某一秒令牌桶中产生了很多令牌，达到令牌桶上限N，缓存在令牌桶中，但是这一秒没有请求进入。
  - 下一秒的前半秒涌入了超过2N个请求，之前缓存的令牌桶的令牌耗尽，同时这一秒又生成了N个令牌，于是总共放行了2N个请求。超出了我们设定的QPS阈值。
- 因此，在使用令牌桶算法时，尽量不要将令牌上限设定到服务能承受的QPS上限。而是预留一定的波动空间，这样我们才能应对突发流量。